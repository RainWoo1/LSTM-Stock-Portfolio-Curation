{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "B_5179g2RH7y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('stock_dataset.db')\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "9Wzqxw8EhOtc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/APS360/hackathon_sample_v2.csv')\n",
        "nasdaq_data = pd.read_csv('/content/drive/MyDrive/APS360/nasdaq-listed.csv')\n",
        "nyse_data = pd.read_csv('/content/drive/MyDrive/APS360/nyse-listed.csv')\n",
        "other_data = pd.read_csv('/content/drive/MyDrive/APS360/other-listed.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J6aMgnVSo4E",
        "outputId": "b3800194-ed00-40ca-db46-31aa2c54452d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_sql('hackathon_sample_v2', conn, if_exists='replace', index=False)\n",
        "nasdaq_data.to_sql('nasdaq_listed', conn, if_exists='replace', index=False)\n",
        "nyse_data.to_sql('nyse_listed', conn, if_exists='replace', index=False)\n",
        "other_data.to_sql('other_listed', conn, if_exists='replace', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqIufdirhrxX",
        "outputId": "6d3cef4c-90c8-47ce-e8b0-6f12382a02ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6409"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_sql('hackathon_sample_v2', conn, if_exists='replace', index=False)\n",
        "\n",
        "nasdaq_data = pd.read_csv('/content/drive/MyDrive/APS360/nasdaq-listed.csv')\n",
        "nasdaq_data.to_sql('nasdaq_listed', conn, if_exists='replace', index=False)\n",
        "\n",
        "nyse_data = pd.read_csv('/content/drive/MyDrive/APS360/nyse-listed.csv')\n",
        "nyse_data.to_sql('nyse_listed', conn, if_exists='replace', index=False)\n",
        "\n",
        "other_data = pd.read_csv('/content/drive/MyDrive/APS360/other-listed.csv')\n",
        "other_data.to_sql('other_listed', conn, if_exists='replace', index=False)\n",
        "cursor.execute('ALTER TABLE nasdaq_listed RENAME COLUMN Symbol TO \"ACT Symbol\";')\n",
        "\n",
        "\n",
        "removed_outdated_tickers = pd.read_sql_query('SELECT * FROM hackathon_sample_v2 WHERE stock_ticker IN (SELECT \"ACT Symbol\" FROM nasdaq_listed UNION SELECT \"ACT Symbol\" FROM nyse_listed UNION SELECT \"ACT Symbol\" FROM other_listed)', conn)\n",
        "removed_outdated_tickers.to_sql('tickerremoved_hackathon_sample_v2', conn, if_exists='replace', index=False)\n",
        "\n",
        "# all companies having complete 12 months data from 2019 to 2023 atleast\n",
        "atleast_five_year_companies = pd.read_sql_query(\"SELECT DISTINCT stock_ticker FROM tickerremoved_hackathon_sample_v2 WHERE year IN (2019, 2020, 2021, 2022, 2023) GROUP BY stock_ticker HAVING COUNT(*) = 60;\",conn)\n",
        "\n",
        "atleast_five_year_companies.to_sql('atleast_five_year_companies', conn, if_exists='replace', index=False)\n",
        "filtered_df = pd.read_sql_query(\"Select year, month, intrinsic_value,stock_exret, stock_ticker,comp_name,be_me,ni_me,fcf_me,betadown_252d, ni_ar1, z_score, ebit_sale, at_turnover, market_equity from tickerremoved_hackathon_sample_v2 where stock_ticker IN (SELECT stock_ticker FROM atleast_five_year_companies) order by stock_ticker, year, month \", conn)\n",
        "\n",
        "filtered_df['prev_intrinsic_value'] = filtered_df['intrinsic_value'].shift(1)\n",
        "filtered_df['next_intrinsic_value'] = filtered_df['intrinsic_value'].shift(-1)\n",
        "\n",
        "\n",
        "filtered_df['prev_stock_exret'] = filtered_df['stock_exret'].shift(1)\n",
        "filtered_df['next_stock_exret'] = filtered_df['stock_exret'].shift(-1)\n",
        "\n",
        "\n",
        "filtered_df['prev_be_me'] = filtered_df['be_me'].shift(1)\n",
        "filtered_df['next_be_me'] = filtered_df['be_me'].shift(-1)\n",
        "\n",
        "\n",
        "filtered_df['prev_ni_me'] = filtered_df['ni_me'].shift(1)\n",
        "filtered_df['next_ni_me'] = filtered_df['ni_me'].shift(-1)\n",
        "\n",
        "\n",
        "filtered_df['prev_fcf_me'] = filtered_df['fcf_me'].shift(1)\n",
        "filtered_df['next_fcf_me'] = filtered_df['fcf_me'].shift(-1)\n",
        "\n",
        "filtered_df['prev_betadown_252d'] = filtered_df['betadown_252d'].shift(1)\n",
        "filtered_df['next_betadown_252d'] = filtered_df['betadown_252d'].shift(-1)\n",
        "\n",
        "filtered_df['prev_ni_ar1'] = filtered_df['ni_ar1'].shift(1)\n",
        "filtered_df['next_ni_ar1'] = filtered_df['ni_ar1'].shift(-1)\n",
        "\n",
        "filtered_df['prev_z_score'] = filtered_df['z_score'].shift(1)\n",
        "filtered_df['next_z_score'] = filtered_df['z_score'].shift(-1)\n",
        "\n",
        "filtered_df['prev_ebit_sale'] = filtered_df['ebit_sale'].shift(1)\n",
        "filtered_df['next_ebit_sale'] = filtered_df['ebit_sale'].shift(-1)\n",
        "\n",
        "filtered_df['prev_at_turnover'] = filtered_df['at_turnover'].shift(1)\n",
        "filtered_df['next_at_turnover'] = filtered_df['at_turnover'].shift(-1)\n",
        "\n",
        "filtered_df['prev_market_equity'] = filtered_df['market_equity'].shift(1)\n",
        "filtered_df['next_market_equity'] = filtered_df['market_equity'].shift(-1)\n",
        "\n",
        "filtered_df['market_equity'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_market_equity'] + row['next_market_equity']) / 2 if pd.isnull(row['market_equity']) and pd.notnull(row['prev_market_equity']) and pd.notnull(row['next_market_equity'])\n",
        "                else row['market_equity'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['intrinsic_value'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_intrinsic_value'] + row['next_intrinsic_value']) / 2 if pd.isnull(row['intrinsic_value']) and pd.notnull(row['prev_intrinsic_value']) and pd.notnull(row['next_intrinsic_value'])\n",
        "                else row['intrinsic_value'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['stock_exret'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_stock_exret'] + row['next_stock_exret']) / 2 if pd.isnull(row['stock_exret']) and pd.notnull(row['prev_stock_exret']) and pd.notnull(row['next_stock_exret'])\n",
        "                else row['stock_exret'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['be_me'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_be_me'] + row['next_be_me']) / 2 if pd.isnull(row['be_me']) and pd.notnull(row['prev_be_me']) and pd.notnull(row['next_be_me'])\n",
        "                else row['be_me'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['ni_me'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_ni_me'] + row['next_ni_me']) / 2 if pd.isnull(row['ni_me']) and pd.notnull(row['prev_ni_me']) and pd.notnull(row['next_ni_me'])\n",
        "                else row['ni_me'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['fcf_me'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_fcf_me'] + row['next_fcf_me']) / 2 if pd.isnull(row['fcf_me']) and pd.notnull(row['prev_fcf_me']) and pd.notnull(row['next_fcf_me'])\n",
        "                else row['fcf_me'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['betadown_252d'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_betadown_252d'] + row['next_betadown_252d']) / 2 if pd.isnull(row['betadown_252d']) and pd.notnull(row['prev_betadown_252d']) and pd.notnull(row['next_betadown_252d'])\n",
        "                else row['betadown_252d'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['ni_ar1'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_ni_ar1'] + row['next_ni_ar1']) / 2 if pd.isnull(row['ni_ar1']) and pd.notnull(row['prev_ni_ar1']) and pd.notnull(row['next_ni_ar1'])\n",
        "                else row['ni_ar1'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['z_score'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_z_score'] + row['next_z_score']) / 2 if pd.isnull(row['z_score']) and pd.notnull(row['prev_z_score']) and pd.notnull(row['next_z_score'])\n",
        "                else row['z_score'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['ebit_sale'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_ebit_sale'] + row['next_ebit_sale']) / 2 if pd.isnull(row['ebit_sale']) and pd.notnull(row['prev_ebit_sale']) and pd.notnull(row['next_ebit_sale'])\n",
        "                else row['ebit_sale'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['at_turnover'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_at_turnover'] + row['next_at_turnover']) / 2 if pd.isnull(row['at_turnover']) and pd.notnull(row['prev_at_turnover']) and pd.notnull(row['next_at_turnover'])\n",
        "                else row['at_turnover'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "filtered_df['market_equity'] = filtered_df.apply(\n",
        "    lambda row: (row['prev_market_equity'] + row['next_market_equity']) / 2 if pd.isnull(row['market_equity']) and pd.notnull(row['prev_market_equity']) and pd.notnull(row['next_market_equity'])\n",
        "                else row['market_equity'],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if feature is still null drop that row\n",
        "filtered_df = filtered_df.dropna(subset=['intrinsic_value', 'market_equity', 'at_turnover', 'ebit_sale', 'z_score', 'ni_ar1', 'betadown_252d', 'fcf_me', 'ni_me', 'be_me', 'stock_exret'])\n",
        "\n",
        "\n",
        "\n",
        "filtered_df['roic'] = filtered_df['ebit_sale'] * filtered_df['at_turnover']\n",
        "\n",
        "filtered_df['bvps'] = filtered_df['be_me']*filtered_df['market_equity']\n",
        "\n",
        "\n",
        "\n",
        "filtered_df['prev_bvps'] = filtered_df.groupby('stock_ticker')['bvps'].shift(1)\n",
        "filtered_df['next_bvps'] = filtered_df.groupby('stock_ticker')['bvps'].shift(-1)\n",
        "\n",
        "\n",
        "filtered_df['bvps_change'] = (filtered_df['bvps'] - filtered_df['prev_bvps']) / filtered_df['prev_bvps']\n",
        "\n",
        "# Calculate the at_turnover change for sales growth change from the previous month\n",
        "filtered_df['prev_at_turnover'] = filtered_df.groupby('stock_ticker')['at_turnover'].shift(1)\n",
        "filtered_df['at_turnover_change'] = (filtered_df['at_turnover'] - filtered_df['prev_at_turnover']) / filtered_df['prev_at_turnover']\n",
        "\n",
        "# Calculate the earnings to price  growth change from the previous month\n",
        "filtered_df['prev_ni_me'] = filtered_df.groupby('stock_ticker')['ni_me'].shift(1)\n",
        "filtered_df['ni_me_change'] = (filtered_df['ni_me'] - filtered_df['prev_ni_me']) / filtered_df['prev_ni_me']\n",
        "\n",
        "# Calculate the FCF to price  growth change from the previous month\n",
        "filtered_df['prev_fcf_me'] = filtered_df.groupby('stock_ticker')['fcf_me'].shift(1)\n",
        "filtered_df['fcf_me_change'] = (filtered_df['fcf_me'] - filtered_df['prev_fcf_me']) / filtered_df['prev_fcf_me']\n",
        "\n",
        "filtered_df.to_sql('filtered_hackathon_sample_v2', conn, if_exists='replace', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WlF5EKEh6oO",
        "outputId": "f25884e7-9042-4e96-bc59-d03510f2f99f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-90a288529335>:140: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['roic'] = filtered_df['ebit_sale'] * filtered_df['at_turnover']\n",
            "<ipython-input-21-90a288529335>:142: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['bvps'] = filtered_df['be_me']*filtered_df['market_equity']\n",
            "<ipython-input-21-90a288529335>:146: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['prev_bvps'] = filtered_df.groupby('stock_ticker')['bvps'].shift(1)\n",
            "<ipython-input-21-90a288529335>:147: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['next_bvps'] = filtered_df.groupby('stock_ticker')['bvps'].shift(-1)\n",
            "<ipython-input-21-90a288529335>:150: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['bvps_change'] = (filtered_df['bvps'] - filtered_df['prev_bvps']) / filtered_df['prev_bvps']\n",
            "<ipython-input-21-90a288529335>:153: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['prev_at_turnover'] = filtered_df.groupby('stock_ticker')['at_turnover'].shift(1)\n",
            "<ipython-input-21-90a288529335>:154: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['at_turnover_change'] = (filtered_df['at_turnover'] - filtered_df['prev_at_turnover']) / filtered_df['prev_at_turnover']\n",
            "<ipython-input-21-90a288529335>:157: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['prev_ni_me'] = filtered_df.groupby('stock_ticker')['ni_me'].shift(1)\n",
            "<ipython-input-21-90a288529335>:158: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['ni_me_change'] = (filtered_df['ni_me'] - filtered_df['prev_ni_me']) / filtered_df['prev_ni_me']\n",
            "<ipython-input-21-90a288529335>:161: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['prev_fcf_me'] = filtered_df.groupby('stock_ticker')['fcf_me'].shift(1)\n",
            "<ipython-input-21-90a288529335>:162: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['fcf_me_change'] = (filtered_df['fcf_me'] - filtered_df['prev_fcf_me']) / filtered_df['prev_fcf_me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/APS360/filtered_hackathon_sample_v2.csv\"\n",
        "filtered_df.to_csv(save_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70y29RiuilQX",
        "outputId": "d3bcd796-1c0f-41d8-dc86-753581555e0e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to: /content/drive/MyDrive/APS360/filtered_hackathon_sample_v2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/APS360/filtered_hackathon_sample_v2.csv\")\n",
        "features = [\n",
        "   \"year\", \"month\", \"intrinsic_value\", \"prev_stock_exret\", \"be_me\", \"ni_me\", \"fcf_me\",\n",
        "    \"betadown_252d\", \"ni_ar1\", \"z_score\", \"ebit_sale\", \"at_turnover\", \"market_equity\",\n",
        "    \"roic\", \"bvps\", \"prev_bvps\", \"bvps_change\", \"prev_at_turnover\"]\n",
        "target = \"stock_exret\"\n",
        "\n",
        "df = df.dropna(subset=features + [target])\n",
        "\n",
        "STOCK_TICKER_COLUMN = \"stock_ticker\"\n",
        "df = df[[STOCK_TICKER_COLUMN] + features + [target]].copy()\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "df[features] = imputer.fit_transform(df[features])\n",
        "df[target] = df[target].fillna(df[target].mean())\n",
        "\n",
        "X = df[features]#input\n",
        "y = df[target]#output\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#initializing\n",
        "rf = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
        "#training\n",
        "rf.fit(X_train, y_train)\n",
        "#values tending to infinte\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "#NaN -> median\n",
        "X_test = X_test.fillna(X_train.median())\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "# Cisco January 2023\n",
        "stock_ticker = \"CSCO\"\n",
        "january_data = df[(df['year'] == 2023) & (df['month'] == 1) & (df[STOCK_TICKER_COLUMN] == stock_ticker)]\n",
        "X_january = january_data[features]\n",
        "y_january_actual = january_data[target]\n",
        "X_january = imputer.transform(X_january)\n",
        "\n",
        "\n",
        "y_january_pred = rf.predict(X_january)\n",
        "january_data[\"predicted_stock_exret\"] = y_january_pred\n",
        "\n",
        "#actual vs predicted\n",
        "print(\"\\nActual vs Predicted Data for January 2023:\")\n",
        "print(january_data[[\"year\", \"month\"] + features + [target, \"predicted_stock_exret\"]])\n",
        "print(january_data[[\"year\", \"month\", STOCK_TICKER_COLUMN] + features + [target, \"predicted_stock_exret\"]])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf_xE8XeTPPi",
        "outputId": "9c1a39d5-42a4-4cf4-b756-2ef67d2f46d7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.0532\n",
            "MSE: 0.0056\n",
            "R² Score: 0.2913\n",
            "\n",
            "Actual vs Predicted Data for January 2023:\n",
            "         year  month    year  month  intrinsic_value  prev_stock_exret  \\\n",
            "23478  2023.0    1.0  2023.0    1.0     103481.01822         -0.045134   \n",
            "\n",
            "          be_me     ni_me    fcf_me  betadown_252d  ...  ebit_sale  \\\n",
            "23478  0.203505  0.060355  0.065142       0.646746  ...   0.273794   \n",
            "\n",
            "       at_turnover  market_equity      roic          bvps     prev_bvps  \\\n",
            "23478     0.538457   195710.02441  0.147426  39828.000007  39827.999991   \n",
            "\n",
            "        bvps_change  prev_at_turnover  stock_exret  predicted_stock_exret  \n",
            "23478  3.982001e-10          0.538457     0.026097              -0.004715  \n",
            "\n",
            "[1 rows x 22 columns]\n",
            "         year  month stock_ticker    year  month  intrinsic_value  \\\n",
            "23478  2023.0    1.0         CSCO  2023.0    1.0     103481.01822   \n",
            "\n",
            "       prev_stock_exret     be_me     ni_me    fcf_me  ...  ebit_sale  \\\n",
            "23478         -0.045134  0.203505  0.060355  0.065142  ...   0.273794   \n",
            "\n",
            "       at_turnover  market_equity      roic          bvps     prev_bvps  \\\n",
            "23478     0.538457   195710.02441  0.147426  39828.000007  39827.999991   \n",
            "\n",
            "        bvps_change  prev_at_turnover  stock_exret  predicted_stock_exret  \n",
            "23478  3.982001e-10          0.538457     0.026097              -0.004715  \n",
            "\n",
            "[1 rows x 23 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "<ipython-input-33-30d7f151b403>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  january_data[\"predicted_stock_exret\"] = y_january_pred\n"
          ]
        }
      ]
    }
  ]
}